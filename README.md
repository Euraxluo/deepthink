<div align="center">
<h1>DeepThink ğŸ¬ğŸ§ </h1>

å— DeepClaude é¡¹ç›®å¯å‘ï¼ŒåŸºäº Ollama å®ç°çš„æœ¬åœ°åŒ–å¤šæ¨¡å‹æ¨ç†æ¡†æ¶ï¼Œé€šè¿‡ç»„åˆå°å‹æ¨¡å‹å®ç°å¼ºå¤§çš„æ¨ç†å’Œå¯¹è¯èƒ½åŠ›ã€‚

[![GitHub license](https://img.shields.io/github/license/euraxluo/deepthink)](https://github.com/euraxluo/deepthink/blob/main/LICENSE.md)
[![Rust](https://img.shields.io/badge/rust-v1.75%2B-orange)](https://www.rust-lang.org/)
[![Ollama](https://img.shields.io/badge/ollama-latest-blue)](https://ollama.ai)

</div>

## Overview

DeepThink æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„æœ¬åœ°åŒ– LLM æ¨ç†æ¡†æ¶ï¼ŒåŸºäº Ollama å®ç°ã€‚å®ƒçš„æ ¸å¿ƒç†å¿µæ˜¯é€šè¿‡ç»„åˆå¤šä¸ªå¼€æºå°å‹æ¨¡å‹ï¼Œå®ç°ç±»ä¼¼å¤§æ¨¡å‹çš„æ¨ç†å’Œå¯¹è¯èƒ½åŠ›ã€‚ç‰¹åˆ«æ˜¯åˆ©ç”¨ DeepSeek-R1 å°æ¨¡å‹ä¼˜ç§€çš„æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰èƒ½åŠ›ï¼Œç»“åˆå…¶ä»–æ¨¡å‹ï¼ˆå¦‚ Qwenï¼‰çš„ç‰¹é•¿ï¼Œåœ¨ä¿æŒè½»é‡çº§éƒ¨ç½²çš„åŒæ—¶æä¾›å¼ºå¤§çš„ AI èƒ½åŠ›ã€‚

## Why DeepThink?

DeepThink æä¾›äº†ä¸€ä¸ªåˆ›æ–°çš„æ–¹æ¡ˆæ¥å®ç°é«˜è´¨é‡çš„ AI å¯¹è¯ï¼š

- **æœ¬åœ°åŒ–éƒ¨ç½²** - åŸºäº Ollama å®ç°å®Œå…¨çš„æœ¬åœ°åŒ–éƒ¨ç½²ï¼Œæ— éœ€äº‘ç«¯ API
- **å°å‹æ¨¡å‹ç»„åˆ** - é€šè¿‡ç»„åˆå¤šä¸ªä¸“ç²¾ä¸åŒä»»åŠ¡çš„å°å‹æ¨¡å‹ï¼Œå®ç°æ¥è¿‘å¤§æ¨¡å‹çš„æ•ˆæœ
- **DeepSeek-R1 æ€ç»´é“¾** - åˆ©ç”¨ DeepSeek-R1 (14B) æ¨¡å‹ä¼˜ç§€çš„æ¨ç†å’Œæ€ç»´é“¾èƒ½åŠ›
- **çµæ´»æ¨¡å‹é€‰æ‹©** - æ”¯æŒ Qwenã€DeepSeek ç­‰å¤šä¸ªå¼€æºæ¨¡å‹ï¼Œå¯æ ¹æ®éœ€æ±‚è‡ªç”±ç»„åˆ
- **é«˜æ€§èƒ½æµå¼å“åº”** - Rust å®ç°çš„é«˜æ€§èƒ½æœåŠ¡ï¼Œæ”¯æŒæµå¼è¾“å‡º
- **å®Œå…¨æ§åˆ¶** - æœ¬åœ°éƒ¨ç½²æ„å‘³ç€å®Œå…¨çš„æ•°æ®éšç§å’Œç³»ç»Ÿæ§åˆ¶

## Getting Started

### Prerequisites

- Rust 1.75 æˆ–æ›´é«˜ç‰ˆæœ¬
- [Ollama](https://ollama.ai) æœ€æ–°ç‰ˆæœ¬
- æ”¯æŒçš„æ¨¡å‹ï¼š
  - deepseek-r1:14b
  - qwen2.5:14b
  - å…¶ä»– Ollama æ”¯æŒçš„æ¨¡å‹

### Configuration

åˆ›å»ºä¸€ä¸ª `config.toml` æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š

```toml
[server]
host = "127.0.0.1"  # æœåŠ¡å™¨ç›‘å¬åœ°å€
port = 3000         # æœåŠ¡å™¨ç›‘å¬ç«¯å£

[endpoints]
deepseek = "http://localhost:11434/v1/chat/completions"  # Ollama API ç«¯ç‚¹
anthropic = "http://localhost:11434/v1/chat/completions"  # Ollama API ç«¯ç‚¹
openai = "http://localhost:11434/v1/chat/completions"     # Ollama API ç«¯ç‚¹
```

### Basic Example

```python
import requests

response = requests.post(
    "http://127.0.0.1:3000/",
    headers={
        "X-DeepSeek-API-Token": "ollama",
        "X-OpenAI-API-Token": "ollama",
        "X-Target-Model": "openai",
        "X-DeepSeek-Endpoint-URL": "http://127.0.0.1:11434/v1/chat/completions",
        "X-OpenAI-Endpoint-URL": "http://localhost:11434/v1/chat/completions"
    },
    json={
        "messages": [
            {"role": "user", "content": "åˆ†æä¸‹é¢è¿™æ®µä»£ç çš„å¤æ‚åº¦"}
        ],
        "stream": False,
        "verbose": False,
        "system": "ä½ æ˜¯ä¸€ä¸ªä»£ç åˆ†æä¸“å®¶",
        "openai_config": {
            "headers": {},
            "body": {
                "model": "qwen2.5:14b"
            }
        },
        "deepseek_config": {
            "headers": {},
            "body": {
                "model": "deepseek-r1:14b"
            }
        }
    }
)

print(response.json())
```

### Streaming Example

```python
import asyncio
import json
import httpx

async def stream_response():
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "POST",
            "http://127.0.0.1:3000/",
            headers={
                "X-DeepSeek-API-Token": "ollama",
                "X-OpenAI-API-Token": "ollama",
                "X-Target-Model": "openai",
                "X-DeepSeek-Endpoint-URL": "http://127.0.0.1:11434/v1/chat/completions",
                "X-OpenAI-Endpoint-URL": "http://localhost:11434/v1/chat/completions"
            },
            json={
                "stream": True,
                "messages": [
                    {"role": "user", "content": "åˆ†æä¸‹é¢è¿™æ®µä»£ç çš„å¤æ‚åº¦"}
                ],
                "openai_config": {
                    "headers": {},
                    "body": {
                        "model": "qwen2.5:14b"
                    }
                },
                "deepseek_config": {
                    "headers": {},
                    "body": {
                        "model": "deepseek-r1:14b"
                    }
                }
            }
        ) as response:
            response.raise_for_status()
            async for line in response.aiter_lines():
                if line:
                    if line.startswith('data: '):
                        data = line[6:]
                        try:
                            parsed_data = json.loads(data)
                            if 'content' in parsed_data:
                                content = parsed_data.get('content', '')[0]['text']
                                print(content, end='', flush=True)
                            else:
                                print(data, flush=True)
                        except json.JSONDecodeError:
                            pass

if __name__ == "__main__":
    asyncio.run(stream_response())
```

## Configuration Options

API æ”¯æŒé€šè¿‡è¯·æ±‚ä½“è¿›è¡Œå¹¿æ³›çš„é…ç½®ï¼š

```json
{
    "messages": [
        {
            "role": "user",
            "content": "ä½ æ˜¯è°?"
        }
    ],
    "system":"ä½ æ˜¯è§’è‰²æ‰®æ¼”åŠ©æ‰‹,ä½ å¯ä»¥å®Œæˆè§’è‰²æ‰®æ¼”,ä½†æ˜¯ä½ éœ€è¦å’Œç”¨æˆ·å¯¹è¯,æ”¶é›†ä½ è¿›è¡Œè§’è‰²ç­çº¿éœ€è¦çš„ä¿¡æ¯",
    "stream": true,
    "verbose": true,
    "openai_config": {
        "headers": {},
        "body": {
            "model": "qwen2.5:14b"
        }
    },
    "deepseek_config": {
        "headers": {},
        "body": {
            "model": "deepseek-r1:14b"
        }
    }
}
```

### æ”¯æŒçš„è¯·æ±‚å¤´

- `X-DeepSeek-API-Token`: Ollama è®¤è¯ä»¤ç‰Œï¼ˆé»˜è®¤ä¸º "ollama"ï¼‰
- `X-OpenAI-API-Token`: Ollama è®¤è¯ä»¤ç‰Œï¼ˆé»˜è®¤ä¸º "ollama"ï¼‰
- `X-Target-Model`: ç›®æ ‡æ¨¡å‹ç±»å‹ï¼ˆ"openai" æˆ– "deepseek"ï¼‰
- `X-DeepSeek-Endpoint-URL`: DeepSeek æ¨¡å‹çš„ Ollama ç«¯ç‚¹
- `X-OpenAI-Endpoint-URL`: OpenAI å…¼å®¹æ¨¡å‹çš„ Ollama ç«¯ç‚¹

## Self-Hosting

DeepThink å¯ä»¥åœ¨æ‚¨è‡ªå·±çš„åŸºç¡€è®¾æ–½ä¸Šéƒ¨ç½²ã€‚æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

### 1. å®‰è£… Ollama

é¦–å…ˆéœ€è¦å®‰è£… Ollama å¹¶ä¸‹è½½æ‰€éœ€æ¨¡å‹ï¼š

```bash
# MacOS
curl -fsSL https://ollama.com/install.sh | sh

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# ä¸‹è½½æ‰€éœ€æ¨¡å‹
ollama pull deepseek-r1:14b
ollama pull qwen2.5:14b
```

### 2. éƒ¨ç½² DeepThink

1. å…‹éš†ä»£ç åº“ï¼š
```bash
git clone https://github.com/euraxluo/deepthink.git
cd deepthink
```

2. é…ç½®ç¯å¢ƒï¼š
   - åˆ›å»º `config.toml` æ–‡ä»¶å¹¶é…ç½®æœåŠ¡å™¨å’Œ Ollama ç«¯ç‚¹
   - ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œï¼ˆé»˜è®¤ç«¯å£ 11434ï¼‰

3. æ„å»ºé¡¹ç›®ï¼š
```bash
cargo build --release
```

4. è¿è¡ŒæœåŠ¡ï¼š
```bash
./target/release/deepthink
```

## å®‰å…¨

- å®Œå…¨æœ¬åœ°åŒ–éƒ¨ç½²ï¼Œæ•°æ®ä¸ä¼šç¦»å¼€æ‚¨çš„åŸºç¡€è®¾æ–½
- æ‰€æœ‰æ¨¡å‹å’ŒæœåŠ¡éƒ½åœ¨æœ¬åœ°è¿è¡Œ
- æ”¯æŒè‡ªå®šä¹‰ Ollama è®¤è¯
- å®šæœŸå®‰å…¨å®¡è®¡å’Œæ›´æ–°

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache 2.0 License è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE.md) æ–‡ä»¶ã€‚

## è‡´è°¢

DeepThink æ˜¯ä¸€ä¸ªå— DeepClaude å¯å‘ï¼Œç”± [Euraxluo](https://github.com/euraxluo) å¼€å‘çš„å…è´¹å¼€æºé¡¹ç›®ã€‚ç‰¹åˆ«æ„Ÿè°¢ï¼š

- [DeepClaude](https://github.com/getasterisk/deepclaude) é¡¹ç›®çš„å¯å‘
- [Ollama](https://ollama.ai) æä¾›çš„æœ¬åœ°æ¨¡å‹éƒ¨ç½²æ–¹æ¡ˆ
- [DeepSeek](https://github.com/deepseek-ai) å¼€æºçš„ä¼˜ç§€æ¨¡å‹
- [Qwen](https://github.com/QwenLM/Qwen2.5) å¼€æºçš„ä¼˜ç§€æ¨¡å‹
- å¼€æºç¤¾åŒºçš„æŒç»­æ”¯æŒ

---

<div align="center">
<a href="https://github.com/euraxluo">Euraxluo</a> built with â¤ï¸
</div>